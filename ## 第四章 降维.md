## 第四章 降维
### PCA主成分分析
-	无监督降维
-	最大化投影目标
	-	去中心化处理
	-	协方差矩阵
	-	特征值分解
	-	取前D大特征向量并将样本映射
	
### LDA线性判别分析
-	有监督降维
-	最大化类间距离+最小化类内距离

## 第五章 无监督学习
### K-means
- 数据预处理（归一化，离群点筛选）

- 随机选取K个簇中心

- 定义代价函数：
  ![image-20200724152243333](C:\Users\kitehuang\AppData\Roaming\Typora\typora-user-images\image-20200724152243333.png)

- 每一个样本分配到距离最近的簇，对于每个簇重新计算中心（不断迭代）

  **缺点**：
（1）需要人工预先确定初始K 值，且该值和真实的数据分布未必吻合。
（2）K均值只能收敛到局部最优，效果受到初始值很大。
（3）易受到噪点的影响。
（4）样本点只能被划分到单一的类中

**PS**：K-mean的迭代算法实际上是一种EM（最大期望算法），解决是概率模型中含有无法观测的隐含变量的参数估计问题。E步：计算隐变量的期望 M步：最大化

### 高斯混合模型
-	假设不同簇中的样本各自服从不同的高斯分布
-	EM迭代：
	-	E步:: 根据当前的参数,计算每个点由分模型生成的概率
	-	M步: 改进每个模型的均值,方差和权重.	
	
## 概率图模型
贝叶斯概率: ![image-20200724162428225](C:\Users\kitehuang\AppData\Roaming\Typora\typora-user-images\image-20200724162428225.png)
-	生成式模型
-	判定式模型